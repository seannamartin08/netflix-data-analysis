{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0919a989",
   "metadata": {},
   "source": [
    "# Netflix Data Project — Clean, Analyze, Visualize & Recommend\n",
    "\n",
    "This notebook is Colab-ready and includes:\n",
    "- Data loading (with Colab upload fallback)\n",
    "- Data cleaning\n",
    "- EDA visualizations\n",
    "- A simple content-based recommender using genres + title text\n",
    "\n",
    "Download this `.ipynb`, open in Colab (File → Upload notebook), and run cells sequentially.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1158e",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "This cell tries `/mnt/data/netflix1.csv` first. If not found (e.g., you're in Colab), it will prompt you to upload the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/mnt/data/netflix1.csv'\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f'Loaded dataset from {csv_path}')\n",
    "else:\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()\n",
    "        fn = list(uploaded.keys())[0]\n",
    "        df = pd.read_csv(fn)\n",
    "        print(f'Loaded uploaded file: {fn}')\n",
    "    except Exception as e:\n",
    "        raise FileNotFoundError(f'Could not find {csv_path} and upload failed. Error: {e}')\n",
    "\n",
    "# Quick safety: show shape\n",
    "print('Shape:', df.shape)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b908ad4",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "- Drop duplicates\n",
    "- Fill common nulls with 'Not Given'\n",
    "- Parse `date_added` and extract year/month/day\n",
    "- Clean `duration` and extract numeric & unit\n",
    "- Create `genres_list` and `top_genre`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c9a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "before = len(df)\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "after = len(df)\n",
    "print('Dropped duplicates:', before-after)\n",
    "\n",
    "# Fill common columns\n",
    "for c in ['director','country','rating']:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna('Not Given')\n",
    "\n",
    "# Date parsing\n",
    "if 'date_added' in df.columns:\n",
    "    df['date_added'] = df['date_added'].astype(str).str.strip()\n",
    "    df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n",
    "    df['added_year'] = df['date_added'].dt.year\n",
    "    df['added_month'] = df['date_added'].dt.month\n",
    "    df['added_day'] = df['date_added'].dt.day\n",
    "\n",
    "# Duration cleaning\n",
    "if 'duration' in df.columns:\n",
    "    df['duration'] = df['duration'].astype(str).str.strip()\n",
    "    df['duration_num'] = df['duration'].str.extract(r'(\\d+)').astype(float)\n",
    "    df['duration_unit'] = df['duration'].str.replace(r'(\\d+)\\s*', '', regex=True).str.strip().replace('', np.nan)\n",
    "\n",
    "# Genres\n",
    "if 'listed_in' in df.columns:\n",
    "    df['listed_in'] = df['listed_in'].astype(str)\n",
    "    df['genres_list'] = df['listed_in'].apply(lambda x: [g.strip() for g in x.split(',')] if pd.notnull(x) else [])\n",
    "    df['top_genre'] = df['genres_list'].apply(lambda x: x[0] if isinstance(x,list) and len(x)>0 else 'Not Given')\n",
    "\n",
    "print('Cleaning done. Columns now:', df.columns.tolist())\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d6c4ab",
   "metadata": {},
   "source": [
    "## Quick summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1bd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:', df.shape)\n",
    "print('\\nMissing values (top 10):')\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print('\\nType counts:')\n",
    "if 'type' in df.columns:\n",
    "    display(df['type'].value_counts())\n",
    "\n",
    "print('\\nTop countries:')\n",
    "if 'country' in df.columns:\n",
    "    display(df['country'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c29611",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "Run the following cells to produce the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "\n",
    "# Type distribution\n",
    "if 'type' in df.columns:\n",
    "    plt.figure()\n",
    "    sns.countplot(data=df, x='type', order=df['type'].value_counts().index)\n",
    "    plt.title('Movies vs TV Shows')\n",
    "    plt.show()\n",
    "\n",
    "# Ratings\n",
    "if 'rating' in df.columns:\n",
    "    r = df['rating'].astype(str).value_counts()\n",
    "    plt.figure()\n",
    "    sns.barplot(x=r.index[:12], y=r.values[:12])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Top Ratings')\n",
    "    plt.show()\n",
    "\n",
    "# Top countries\n",
    "if 'country' in df.columns:\n",
    "    tc = df['country'].astype(str).value_counts().head(10)\n",
    "    plt.figure()\n",
    "    sns.barplot(x=tc.index, y=tc.values)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Top 10 countries by content')\n",
    "    plt.show()\n",
    "\n",
    "# Monthly releases (if date parsed)\n",
    "if 'added_month' in df.columns and 'type' in df.columns:\n",
    "    mm = df[df['type']=='Movie']['added_month'].value_counts().sort_index()\n",
    "    ms = df[df['type']=='TV Show']['added_month'].value_counts().sort_index()\n",
    "    plt.figure()\n",
    "    plt.plot(mm.index, mm.values, marker='o', label='Movies')\n",
    "    plt.plot(ms.index, ms.values, marker='o', label='TV Shows')\n",
    "    plt.xticks(range(1,13))\n",
    "    plt.legend()\n",
    "    plt.title('Monthly additions')\n",
    "    plt.show()\n",
    "\n",
    "# Word cloud of titles\n",
    "if 'title' in df.columns:\n",
    "    titles = df['title'].dropna().astype(str).tolist()\n",
    "    if titles:\n",
    "        text = ' '.join(titles)\n",
    "        wc = WordCloud(width=1000, height=400, background_color='white').generate(text)\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title('Word Cloud of Titles')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d1cd41",
   "metadata": {},
   "source": [
    "## Simple content-based recommender (genres + title)\n",
    "We build a combined text field from `top_genre` and `title`, vectorize with TF-IDF, and for a given title return the most similar titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for recommender\n",
    "rec_df = df.copy()\n",
    "rec_df['rec_text'] = rec_df.get('top_genre', '').fillna('') + ' ' + rec_df.get('title', '').fillna('')\n",
    "rec_df['rec_text'] = rec_df['rec_text'].astype(str)\n",
    "\n",
    "# TF-IDF\n",
    "tf = TfidfVectorizer(stop_words='english')\n",
    "X = tf.fit_transform(rec_df['rec_text'])\n",
    "cos_sim = linear_kernel(X, X)\n",
    "print('Recommender prepared. Rows:', rec_df.shape[0])\n",
    "\n",
    "# Helper function\n",
    "def recommend(title, topn=5):\n",
    "    title = str(title).strip()\n",
    "    if title not in rec_df['title'].astype(str).values:\n",
    "        print('Title not found. Try a different one.\\nExample titles:')\n",
    "        display(rec_df['title'].head(10))\n",
    "        return []\n",
    "    idx = rec_df[rec_df['title'].astype(str)==title].index[0]\n",
    "    sim_scores = list(enumerate(cos_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = [s for s in sim_scores if s[0] != idx]\n",
    "    top = sim_scores[:topn]\n",
    "    results = rec_df.iloc[[i[0] for i in top]][['title','type','top_genre']]\n",
    "    display(results)\n",
    "    return results\n",
    "\n",
    "# Example (uncomment and run with a title that exists in your dataset):\n",
    "# recommend('Midnight Mass', topn=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6e2d1",
   "metadata": {},
   "source": [
    "## Save cleaned CSV (optional)\n",
    "This will save the cleaned dataset to `/mnt/data/netflix_final_cleaned.csv`. Change the path if you want to save elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61119ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = '/mnt/data/netflix_final_cleaned.csv'\n",
    "df.to_csv(outp, index=False)\n",
    "print('Saved cleaned CSV to', outp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d834f7",
   "metadata": {},
   "source": [
    "## Done\n",
    "Download the notebook file `netflix_final_notebook.ipynb` and upload it to Google Colab or run locally in Jupyter. If you want additions (more ML, SQL cleaning, or interactive plots) tell me which and I'll add them."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
